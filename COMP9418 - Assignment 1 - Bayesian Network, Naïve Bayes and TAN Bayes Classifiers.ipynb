{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9418 - Assignment 1 - Bayesian Network, Na√Øve Bayes and TAN Bayes Classifiers\n",
    "\n",
    "## UNSW Sydney, September 2022\n",
    "\n",
    "- Stanley Zhou - z5255741\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "**Submission deadline:** Sunday, 16th October 2022, at 18:00:00 AEDT.\n",
    "\n",
    "**Late Submission Policy:** The penalty is set at $5\\%$ per late day for a maximum of 5 days. This is the UNSW standard late penalty. For example, if an assignment receives an on-time mark of 70/100 and is submitted three days late, it will receive a mark reduction of $70/100*15\\%$. After five days, the assignment will receive a mark reduction of $100\\%$.\n",
    "\n",
    "**Form of Submission:** This is an **individual** or group of **two students** assignment. Write the name(s) and zID(s) in this Jupyter notebook. **If submitted in a group, only one member should submit the assignment. Also, create a group on WebCMS by clicking on Groups and Create and include both group members**.\n",
    "\n",
    "You can reuse any piece of source code developed in the tutorials.\n",
    "\n",
    "You can submit your solution via [WebCMS](https://webcms3.cse.unsw.edu.au/COMP9418/22T3).\n",
    "\n",
    "Alternatively, you can submit your solution using give. On a CSE Linux machine, type the following on the command line:\n",
    "\n",
    "``$ give cs9418 ass1 solution.zip``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical prerequisites\n",
    "\n",
    "These are the libraries you are allowed to use. No other libraries will be accepted. Make sure you are using Python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allowed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import heapq as pq\n",
    "import matplotlib as mp\n",
    "import math\n",
    "from itertools import product, combinations\n",
    "from graphviz import Digraph\n",
    "from tabulate import tabulate\n",
    "import copy\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the python files we developed in tutorials or any other code from the tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DiscreteFactors import Factor\n",
    "from Graph import Graph\n",
    "from BayesNet import BayesNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0 - Initialise graph\n",
    "\n",
    "Create a graph ``G`` that represents the following network by filling in the edge lists.\n",
    "![Bayes Net](BayesNet.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Graph({\n",
    "    \"LymphNodes\": [],\n",
    "    'Metastasis': [\"LymphNodes\"],\n",
    "    \"BC\": [\"Metastasis\",\"Mass\",\"AD\",\"NippleDischarge\",\"SkinRetract\",\"MC\"],\n",
    "    \"Age\": [\"BC\"],\n",
    "    \"Location\": [\"BC\"],\n",
    "    \"MC\": [],\n",
    "    \"SkinRetract\": [],\n",
    "    \"NippleDischarge\": [],\n",
    "    \"AD\": [\"FibrTissueDev\"],\n",
    "    \"FibrTissueDev\": [\"NippleDischarge\",\"SkinRetract\",\"Spiculation\"],\n",
    "    \"Spiculation\": [\"Margin\"],\n",
    "    \"Margin\": [],\n",
    "    \"Mass\": [\"Margin\",\"Shape\",\"Size\"],\n",
    "    \"Shape\": [],\n",
    "    \"Size\": [],\n",
    "    \"BreastDensity\": [\"Mass\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open('bc.csv') as file:\n",
    "    data = pd.read_csv(file)\n",
    "\n",
    "# remove 2 variables from data (because we are pretending we don't know this information)\n",
    "if 'Metastasis' in data:\n",
    "    del data['Metastasis']\n",
    "if 'LymphNodes' in data:\n",
    "    del data['LymphNodes']\n",
    "\n",
    "# remove same 2 nodes from graph\n",
    "G.remove_node('Metastasis')\n",
    "G.remove_node('LymphNodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10 Marks] Task 1 - Efficient d-separation test\n",
    "\n",
    "Implement the efficient version of the d-separation algorithm in a function ``d_separation(G, X, Z, Y)`` that return a boolean: ``True`` if **X** is d-separated from **Y** given **Z** in the graph $G$ and ``False`` otherwise.\n",
    "\n",
    "* **X**,**Y** and **Z** are python sets, each containing a set of variable names. \n",
    "* Variable names may be strings or integers and can be assumed to be nodes of the graph $G$. \n",
    "* $G$ is a directed graph object as defined in tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_undirected_graph(g):\n",
    "    \n",
    "    g_prime = copy.deepcopy(g)\n",
    "    keys = list(g.adj_list.keys())\n",
    "    for key in keys:\n",
    "        children = g.children(key)\n",
    "        for child in children:\n",
    "            g_prime.add_edge(child, key, directed=True)\n",
    "    return g_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop your code for d_separation(G, X, Z, Y) in this cell\n",
    "\n",
    "def d_separation(G, X, Z, Y):\n",
    "    '''\n",
    "    Arguments:\n",
    "        G:   is an object of type Graph (the class you developed in tutorial 1).\n",
    "        X,Z and Y:  are python set objects.\n",
    "    Returns:\n",
    "        True if X is d-separared of Y given Z or False otherwise.\n",
    "    '''\n",
    "    g_prime = copy.deepcopy(G)\n",
    "\n",
    "    while True:\n",
    "        keys = list(set(g_prime.adj_list.keys()) - X - Y - Z)\n",
    "        has_leaf = False\n",
    "        for key in keys:\n",
    "            if len(g_prime.children(key)) == 0:\n",
    "                g_prime.remove_node(key)\n",
    "                has_leaf = True\n",
    "                break\n",
    "        if not has_leaf:\n",
    "            break\n",
    "\n",
    "    for key in list(Z):\n",
    "        children = g_prime.children(key)\n",
    "        for child in children:\n",
    "            g_prime.adj_list[key].remove(child)\n",
    "    \n",
    "    g_prime = get_undirected_graph(g_prime)\n",
    "    g_prime.colour = {node: 'white' for node in g_prime.adj_list.keys()}\n",
    "    \n",
    "    for key in list(X):\n",
    "        g_prime.dfs(key)\n",
    "        \n",
    "    for key in list(Y):\n",
    "        if g_prime.colour[key] == 'white':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "## Note: More hidden tests will be used. You should make more tests yourself.\n",
    "\n",
    "def test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case !!!\")\n",
    "        \n",
    "test(d_separation(G, set(['Age']), set(['BC']), set(['AD'])))\n",
    "test(not d_separation(G, set(['Spiculation', 'SkinRetract']), set(['MC', 'Size']), set(['Age'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 2 - Markov blanket\n",
    "\n",
    "The Markov blanket for a variable $X$ is a set of variables that, when observed, will render every other variable irrelevant to $X$. If the distribution is induced by DAG $G$, then a Markov blanket for variable $X$ can be constructed using $X$'s parents, children, and spouses in $G$. A variable $Y$ is a spouse of $X$ if the two variables have a common child in $G$.\n",
    "\n",
    "In this exercise, we will implement a function `Markov(G, X)` that returns a python set with the Markov blanket of $X$ in $G$ as described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop your code for Markov_blanket(G, X) in this cell\n",
    "\n",
    "def Markov_blanket(G, X):\n",
    "    '''\n",
    "    Arguments:\n",
    "        G:   is an object of type Graph (the class you developed in tutorial 1)\n",
    "        X:   is a node (variable) in G.\n",
    "    Returns: \n",
    "        A python set with the Markov blanked of X in G\n",
    "    '''\n",
    "    g = copy.deepcopy(G)\n",
    "    mb = set()\n",
    "    \n",
    "    # children\n",
    "    mb = mb.union(set(g.children(X)))\n",
    "    \n",
    "    # parents\n",
    "    g_t = g.transpose()\n",
    "    mb = mb.union(set(g_t.children(X)))\n",
    "    \n",
    "    #spouses\n",
    "    children = g.children(X)\n",
    "    for child in children:\n",
    "        mb = mb.union(set(g_t.children(child)))\n",
    "    \n",
    "    mb.remove(X)\n",
    "    return mb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def Markov_blanket(G, X):\n",
    "    '''\n",
    "    Arguments:\n",
    "        G:   is an object of type Graph (the class you developed in tutorial 1)\n",
    "        X:   is a node (variable) in G.\n",
    "    Returns: \n",
    "        A python set with the Markov blanked of X in G\n",
    "    '''\n",
    "    G = copy.deepcopy(G)\n",
    "    Mb = set()\n",
    "    \n",
    "    Mb.update(G.children(X))\n",
    "    GT = G.transpose() \n",
    "    Mb.update(GT.children(X))\n",
    "    for Y in G.children(X):\n",
    "        Mb.update(GT.children(Y))\n",
    "    Mb.discard(X)\n",
    "    return Mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "## Note: More hidden tests will be used. You should make more tests yourself.\n",
    "\n",
    "def test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case !!!\")\n",
    "\n",
    "test(Markov_blanket(G, 'Mass') == set(['Margin', 'Size', 'Shape', 'BreastDensity', 'BC', 'Spiculation']))\n",
    "test(Markov_blanket(G, 'Age') == set(['Location', 'BC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Test code to copy  #\n",
    "######################\n",
    "\n",
    "test(Markov_blanket(G, 'BC') == set(['FibrTissueDev', 'NippleDischarge', 'MC', 'Age', 'Location', 'Mass', 'AD', 'BreastDensity', 'SkinRetract']))\n",
    "test(Markov_blanket(G, 'Age') == set(['Location', 'BC']))\n",
    "test(Markov_blanket(G, 'Location') == set(['Age', 'BC']))\n",
    "test(Markov_blanket(G, 'MC') == set(['BC']))\n",
    "test(Markov_blanket(G, 'SkinRetract') == set(['FibrTissueDev', 'BC']))\n",
    "test(Markov_blanket(G, 'NippleDischarge') == set(['FibrTissueDev', 'BC']))\n",
    "test(Markov_blanket(G, 'AD') == set(['FibrTissueDev', 'BC']))\n",
    "test(Markov_blanket(G, 'FibrTissueDev') == set(['NippleDischarge', 'AD', 'BC', 'Spiculation', 'SkinRetract']))\n",
    "test(Markov_blanket(G, 'Spiculation') == set(['Margin', 'FibrTissueDev', 'Mass']))\n",
    "test(Markov_blanket(G, 'Margin') == set(['Spiculation', 'Mass']))\n",
    "test(Markov_blanket(G, 'Mass') == set(['Margin', 'Size', 'Shape', 'BreastDensity', 'BC', 'Spiculation']))\n",
    "test(Markov_blanket(G, 'Shape') == set(['Mass']))\n",
    "test(Markov_blanket(G, 'Size') == set(['Mass']))\n",
    "test(Markov_blanket(G, 'BreastDensity') == set(['Mass', 'BC']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting Tasks 1 and 2 together\n",
    "\n",
    "This task is optional and will not be marked, but you can use it to test your code further. According to the Markov blanket definition: A Markov blanket for a variable $X \\in \\textbf{X}$ is the set of variables $\\textbf{B} \\subseteq \\textbf{X}$ such that $X \\notin \\textbf{B}$ and $X \\perp \\textbf{X} \\setminus (\\textbf{B} \\cup \\{ X \\}) | \\textbf{B}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop your code to test your d-separation and Markov blanket implementations using the definition above.\n",
    "\n",
    "set_X = {...}                                        # Set of all nodes in the graph\n",
    "for X in set_X:\n",
    "    mb = ...                                         # Markov_blanket of X\n",
    "    ...                                              # Independence test according to the definition above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 3 - Learning the outcome space from data\n",
    "\n",
    "Now, we will implement a series of functions to learn Bayesian network parameters from data. We will start by learning the outcome space of the variables in a Bayesian network. Remind from the tutorials that the outcome space is a python dictionary that maps the variable names to a tuple with the possible values this variable can have.\n",
    "\n",
    "Implement a function ``learn_outcome_space(dataframe)`` that learns the outcome space (the valid values for each variable) from the pandas dataframe ``dataframe`` and returns a dictionary ``outcomeSpace`` with these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop your code for learn_outcome_space(dataframe) in this cell\n",
    "\n",
    "def learn_outcome_space(dataframe):\n",
    "    '''\n",
    "    Arguments:\n",
    "        dataframe:    A pandas dataframe\n",
    "    Returns: \n",
    "        outcomeSpace: A dictionary. e.g. {'A':('True', 'False'), 'B':('up','down','left'), 'C':(1,2,3,4)}\n",
    "    '''\n",
    "    outcome_space = {}\n",
    "    for col in dataframe.columns:\n",
    "        outcome_space[col] = tuple(set(dataframe[col]))\n",
    "    \n",
    "    return outcome_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "## Note: More hidden tests will be used. You should make more tests yourself.\n",
    "\n",
    "outcomeSpace = learn_outcome_space(data)\n",
    "\n",
    "outcomes = outcomeSpace['BreastDensity']\n",
    "answer = ('high', 'medium', 'low')\n",
    "test(len(outcomes) == len(answer) and set(outcomes) == set(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 4 - Estimate Bayesian network parameters from data\n",
    "\n",
    "Implement a method ``model.learn_parameters(dataframe, alpha=1)`` that learns the parameters of the Bayesian Network `model`. This function should do the same as the ``learn_parameters`` function from tutorials, but it should also implement laplacian smoothing with parameter $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allEqualThisIndex(dict_of_arrays, **fixed_vars):\n",
    "\n",
    "    # base index is a boolean vector, everywhere true\n",
    "    first_array = dict_of_arrays[list(dict_of_arrays.keys())[0]]\n",
    "    index = np.ones_like(first_array, dtype=np.bool_)\n",
    "    for var_name, var_val in fixed_vars.items():\n",
    "        index = index & (np.asarray(dict_of_arrays[var_name])==var_val)\n",
    "    return index\n",
    "\n",
    "def estimateFactor(data, var_name, parent_names, outcomeSpace, alpha):\n",
    "    \n",
    "    var_outcomes = outcomeSpace[var_name]\n",
    "    parent_outcomes = [outcomeSpace[var] for var in (parent_names)]\n",
    "    # cartesian product to generate a table of all possible outcomes\n",
    "    all_parent_combinations = product(*parent_outcomes)\n",
    "\n",
    "    f = Factor(list(parent_names)+[var_name], outcomeSpace)\n",
    "    \n",
    "    for i, parent_combination in enumerate(all_parent_combinations):\n",
    "        parent_vars = dict(zip(parent_names, parent_combination))\n",
    "        parent_index = allEqualThisIndex(data, **parent_vars)\n",
    "        for var_outcome in var_outcomes:\n",
    "            var_index = (np.asarray(data[var_name])==var_outcome)\n",
    "            f[tuple(list(parent_combination)+[var_outcome])] = ((var_index & parent_index).sum() + alpha)/(parent_index.sum() + alpha * len(var_outcomes))\n",
    "            \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_parameters(self, dataframe, alpha) in this cell\n",
    "\n",
    "class BayesNet(BayesNet):\n",
    "    def learn_parameters(self, dataframe, alpha=1):\n",
    "        '''\n",
    "        Arguments:\n",
    "            data:    A pandas dataframe\n",
    "            alpha:   Laplacian smoothing parameter\n",
    "        '''        \n",
    "        graphT = self.graph.transpose()\n",
    "        for node, parents in graphT.adj_list.items():\n",
    "            self.factors[node] = estimateFactor(data, node, parents, self.outcomeSpace, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.248000399920016\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "## Note: More hidden tests will be used. You should make more tests yourself.\n",
    "\n",
    "outcomeSpace = learn_outcome_space(data)\n",
    "model = BayesNet(G, outcomeSpace=outcomeSpace)\n",
    "\n",
    "model.learn_parameters(data, alpha=1)\n",
    "\n",
    "print(model.factors['Age']['35-49'])\n",
    "test(model.factors['Age']['35-49'] == 0.248000399920016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     0.650421\n",
       "Yes    0.349579\n",
       "Name: FibrTissueDev, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = data[data['AD'] == 'No']\n",
    "temp['FibrTissueDev'].value_counts() / temp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ïí‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïï\n",
      "‚îÇ AD   ‚îÇ FibrTissueDev   ‚îÇ       Pr ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ No   ‚îÇ No              ‚îÇ 0.650403 ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ No   ‚îÇ Yes             ‚îÇ 0.349597 ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ Yes  ‚îÇ No              ‚îÇ 0.256064 ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ Yes  ‚îÇ Yes             ‚îÇ 0.743936 ‚îÇ\n",
      "‚ïò‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïõ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.factors['FibrTissueDev'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 5 - Bayesian network classification\n",
    "\n",
    "Design a new method ``model.predict(class_var, evidence)`` that implements the classification with complete data. This function should return the MPE value for the attribute `class_var` given the evidence. As we are working with complete data, `evidence` is an instantiation for all variables in the Bayesian network `model` but `class_var`.\n",
    "\n",
    "**Implement the efficient classification procedure discussed in the lectures. Assure that you only join the necessary factors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for predict(self, class_var, evidence) in this cell\n",
    "\n",
    "class BayesNet(BayesNet):\n",
    "    \n",
    "    def interactionGraph(self):\n",
    "        \n",
    "        g = Graph()\n",
    "        for var in self.factors.keys():\n",
    "            g.add_node(var) \n",
    "        for factor in self.factors.values():\n",
    "            for var1 in factor.domain:\n",
    "                for var2 in factor.domain:\n",
    "                    if var1 != var2 and var1 not in g.children(var2):\n",
    "                        g.add_edge(var1, var2, directed=False)\n",
    "        return g\n",
    "    \n",
    "    def minDegree(self):\n",
    "        ig = self.interactionGraph()\n",
    "        order = [] \n",
    "        while len(ig) > 0:\n",
    "            minDegree = math.inf\n",
    "            for var in ig:\n",
    "                if len(ig.children(var)) < minDegree:\n",
    "                    minDegree = len(ig.children(var)) \n",
    "                    minVar = var \n",
    "            for var1, var2 in combinations(ig.children(minVar), 2):\n",
    "                if var1 not in ig.children(var2):\n",
    "                    ig.add_edge(var1, var2, directed=False)\n",
    "            order.append(minVar) \n",
    "            ig.remove_node(minVar)             \n",
    "        return order\n",
    "    \n",
    "    def VE(self, order):\n",
    "        \n",
    "        factorList = list(self.factors.values())\n",
    "        for var in order:\n",
    "            newFactor = Factor(tuple(), self.outcomeSpace)\n",
    "            first = True\n",
    "            updatedFactorsList = list()            \n",
    "\n",
    "            for f in factorList:\n",
    "                if var in f.domain:\n",
    "                    newFactor = newFactor.join(f)\n",
    "                    if not first: pass\n",
    "                    first = False\n",
    "                else:\n",
    "                    updatedFactorsList.append(f)\n",
    "                    \n",
    "            newFactor = newFactor.marginalize(var) # TODO marginalize out `var`\n",
    "            updatedFactorsList.append(newFactor)\n",
    "            factorList = updatedFactorsList\n",
    "        returnFactor = Factor(tuple(), self.outcomeSpace)\n",
    "        for f in factorList:\n",
    "            returnFactor = returnFactor*f\n",
    "        return returnFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesNet(BayesNet):\n",
    "    def predict(self, class_var, evidence):\n",
    "        '''\n",
    "        Arguments:\n",
    "            class_var:   Variable identifier to be classified\n",
    "            evidence:    Python dictionary with one instantiation to all variables but class_var\n",
    "        Returns:\n",
    "            The MPE value (class label) of class_var given evidence\n",
    "        '''        \n",
    "        factors = copy.deepcopy(self.factors)\n",
    "        blanket = Markov_blanket(self.graph, class_var)\n",
    "        \n",
    "        factor = self.factors[class_var]\n",
    "        for b in blanket:\n",
    "            factor = factor.join(self.factors[b])\n",
    "            factor = factor.evidence(**evidence)\n",
    "        \n",
    "        index = np.argmax(factor.table)\n",
    "        #print(factor.normalize())\n",
    "        return self.outcomeSpace[class_var][index]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "## Note: More hidden tests will be used. You should make more tests yourself.\n",
    "\n",
    "outcomeSpace = learn_outcome_space(data)\n",
    "model = BayesNet(G, outcomeSpace=outcomeSpace)\n",
    "model.learn_parameters(data, alpha=1)\n",
    "\n",
    "evidence = {'Age': '35-49', \n",
    "    'Location': 'LolwOutQuad', \n",
    "    'MC': 'No', \n",
    "    'SkinRetract': 'No', \n",
    "    'NippleDischarge': 'No',\n",
    "    'AD': 'No',\n",
    "    'FibrTissueDev': 'No', \n",
    "    'Spiculation': 'No',\n",
    "    'Margin': 'Well-defined', \n",
    "    'Mass': 'No',\n",
    "    'Shape': 'Other', \n",
    "    'Size': '<1cm',\n",
    "    'BreastDensity': 'high'}\n",
    "\n",
    "print(model.predict('BC', evidence))\n",
    "test(model.predict('BC', evidence) == 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Test code to copy  #\n",
    "######################\n",
    "\n",
    "evidence = data.iloc[42].to_dict()\n",
    "del evidence['BC']\n",
    "test(model.predict('BC', evidence) == 'No')\n",
    "\n",
    "evidence = data.iloc[42].to_dict()\n",
    "del evidence['AD']\n",
    "test(model.predict('AD', evidence) == 'No')\n",
    "\n",
    "evidence = data.iloc[42].to_dict()\n",
    "del evidence['Size']\n",
    "test(model.predict('Size', evidence) == '<1cm')\n",
    "\n",
    "evidence = data.iloc[42].to_dict()\n",
    "del evidence['Margin']\n",
    "test(model.predict('Margin', evidence) == 'Well-defined')\n",
    "\n",
    "evidence = data.iloc[42].to_dict()\n",
    "del evidence['BreastDensity']\n",
    "test(model.predict('BreastDensity', evidence) == 'medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 6 - Bayesian network accuracy estimation\n",
    "\n",
    "Design a new function ``assess_bayes_net(model, dataframe, class_var)`` that uses the test cases in ``dataframe`` to assess the Bayesian network `model` performance at classifying the variable `class_var`. This function will return the accuracy of the Bayesian network according to the examples in ``dataframe``.\n",
    "\n",
    "Remind that accuracy is the ratio of the number of correct predictions to the total number of cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for assess_bayes_net(model, dataframe, class_var) in this cell\n",
    "\n",
    "\n",
    "def assess_bayes_net(model, dataframe, class_var='BC'):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model:     Bayesian Network object\n",
    "        dataframe: a Pandas dataframe object\n",
    "        class_var: Variable identifier to be classified\n",
    "    Returns:\n",
    "        The accuracy of the Bayesian network model in classifying the cases in dataframe\n",
    "    '''     \n",
    "    count, correct = 0, 0\n",
    "    records = data.to_dict(orient='records')\n",
    "    for row in records:\n",
    "        # print(f'currently predicting: {count}')\n",
    "        Y = row.pop(class_var)\n",
    "        Y_hat = model.predict(class_var, row)\n",
    "        \n",
    "        if Y == Y_hat:\n",
    "            correct += 1\n",
    "        count += 1\n",
    "    \n",
    "    return correct/ count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_bayes_net2(model, dataframe, var='BC'):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model:     Bayesian Network object\n",
    "        dataframe: a Pandas dataframe object\n",
    "        class_var: Variable identifier to be classified\n",
    "    Returns:\n",
    "        The accuracy of the Bayesian network model in classifying the cases in dataframe\n",
    "    ''' \n",
    "    true_labels = dataframe[var]\n",
    "    predictions = []\n",
    "    \n",
    "    for i, evidence in enumerate(dataframe.to_dict(orient='records')):\n",
    "        del evidence[var]\n",
    "        pred = model.predict(var, evidence)\n",
    "        predictions.append(pred)\n",
    "        \n",
    "    acc = np.count_nonzero(true_labels == predictions)\n",
    "    return acc, true_labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'small_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-698a9c2259fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massess_bayes_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmall_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FibrTissueDev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massess_bayes_net_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmall_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FibrTissueDev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'small_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(assess_bayes_net(model, small_data, 'FibrTissueDev'))\n",
    "print(assess_bayes_net_solution(model, small_data, 'FibrTissueDev'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5645, 20000)\n",
      "(571, (2000,))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(assess_bayes_net(model, small_data, 'Location'))\n",
    "print(assess_bayes_net_solution(model, small_data, 'Location'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17016, 20000)\n",
      "(1708, (2000,))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(assess_bayes_net(model, small_data, 'Size'))\n",
    "print(assess_bayes_net_solution(model, small_data, 'Size'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If these tests break, try changing the \n",
      "dataset to full sized (and deduct 1 mark). Note that the tests are designed for the small dataset\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-76ad8014806b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massess_bayes_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmall_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.84225\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massess_bayes_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmall_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FibrTissueDev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-f9b12587c1ab>\u001b[0m in \u001b[0;36massess_bayes_net\u001b[0;34m(model, dataframe, class_var)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# print(f'currently predicting: {count}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mY_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY_hat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-bb8086f91810>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, class_var, evidence)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mMPE\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mof\u001b[0m \u001b[0mclass_var\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mevidence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         '''        \n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mfactors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mblanket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMarkov_blanket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_tuple\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_deepcopy_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0;31m# We're not going to put the tuple in the memo, but it's still important we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;31m# check for it, in case the tuple contains recursive mutable structures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_deepcopy_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0;31m# We're not going to put the tuple in the memo, but it's still important we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;31m# check for it, in case the tuple contains recursive mutable structures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"If these tests break, try changing the \\ndataset to full sized (and deduct 1 mark). Note that the tests are designed for the small dataset\")\n",
    "small_data = data.head(2000)\n",
    "\n",
    "model = BayesNet(G, outcomeSpace)\n",
    "model.learn_parameters(small_data, alpha=1)\n",
    "\n",
    "acc = assess_bayes_net(model, small_data, 'BC')\n",
    "test(abs(acc-0.84225) < 0.001)\n",
    "acc = assess_bayes_net(model, small_data, 'FibrTissueDev')\n",
    "test(abs(acc-0.8355) < 0.001)\n",
    "acc = assess_bayes_net(model, small_data, 'Location')\n",
    "test(abs(acc-0.294) < 0.001)\n",
    "acc = assess_bayes_net(model, small_data, 'Size')\n",
    "test(abs(acc-0.854) < 0.001)\n",
    "\n",
    "print(\"Testing that unnecessary factors are not used\")\n",
    "# Confirm that they are not using the irrelevant \"BreastDensity\" table\n",
    "# check that they are only using tables in the markov blanket, which are the tables of children and parents.\n",
    "try:\n",
    "    if \"BreastDensity\" in model.factors:\n",
    "        del model.factors[\"BreastDensity\"]\n",
    "    assess_bayes_net(model, small_data, 'BC')\n",
    "    print(\"Passed test case\")\n",
    "except:\n",
    "    print(\"Failed test case\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 7 - Bayesian network assessment with cross-validation\n",
    "\n",
    "Implement a function called `cross_validation_bayes_net(G, dataframe, class_var, k)`, compute and report the average accuracy of the Bayesian network specified by the graph `G` over a $k=10$ cross-validation runs as well as the standard deviation. A scaffold for this function is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for cross_validation_bayes_net(G, dataframe, class_var, k) in this cell\n",
    "# Answer\n",
    "\n",
    "## Develop your code for assess_bayes_net(model, dataframe, class_var) in this cell\n",
    "\n",
    "def assess_bayes_net(model, dataframe, var='BC'):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model:     Bayesian Network object\n",
    "        dataframe: a Pandas dataframe object\n",
    "        class_var: Variable identifier to be classified\n",
    "    Returns:\n",
    "        The accuracy of the Bayesian network model in classifying the cases in dataframe\n",
    "    ''' \n",
    "    \n",
    "    true_labels = dataframe[var]\n",
    "    predictions = []\n",
    "    \n",
    "    for i, evidence in enumerate(dataframe.to_dict(orient='records')):\n",
    "        del evidence[var]\n",
    "        pred = model.predict(var, evidence)\n",
    "        predictions.append(pred)\n",
    "        \n",
    "    acc = np.mean(true_labels == predictions)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def cross_validation_bayes_net(G, dataframe, class_var='BC', k=10):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model:      Bayesian Network object\n",
    "        dataframe:  a Pandas dataframe object\n",
    "        class_var:  Variable identifier to be classified\n",
    "        k:          number of cross-validation folds\n",
    "    Returns:\n",
    "        The mean accuracy and standand deviation of model across the k folds\n",
    "    '''      \n",
    "    accuracy_list = []\n",
    "    \n",
    "    kf = KFold(n_splits=k, shuffle = True, random_state = 42)\n",
    "    for train, test in kf.split(dataframe):\n",
    "      \n",
    "        # train a model with learn_parameters\n",
    "        model = BayesNet(G, outcomeSpace)\n",
    "        model.learn_parameters(train, alpha=1)\n",
    "        #print(type(train))\n",
    "        # test the model with assess_bayes_net\n",
    "        acc = assess_bayes_net(model, pd.DataFrame(test), class_var)\n",
    "        \n",
    "        accuracy_list.append(acc)\n",
    "    return np.mean(accuracy_list), np.std(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'BC'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-bcc47e49b385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation_bayes_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'time taken = {dt.now() - start}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.85\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-5810715bf3ee>\u001b[0m in \u001b[0;36mcross_validation_bayes_net\u001b[0;34m(G, dataframe, class_var, k)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m#print(type(train))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# test the model with assess_bayes_net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massess_bayes_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0maccuracy_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-5810715bf3ee>\u001b[0m in \u001b[0;36massess_bayes_net\u001b[0;34m(model, dataframe, var)\u001b[0m\n\u001b[1;32m     14\u001b[0m     ''' \n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BC'"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "start = dt.now()\n",
    "acc, stddev = cross_validation_bayes_net(G, data, 'BC', 10)\n",
    "print(f'time taken = {dt.now() - start}')\n",
    "test(abs(acc - 0.85) < 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-f5e06a724deb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation_bayes_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Average accuracy: {acc} ¬± {stddev}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-179598895b0a>\u001b[0m in \u001b[0;36mcross_validation_bayes_net\u001b[0;34m(G, dataframe, class_var, k)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m#print(type(train))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# test the model with assess_bayes_net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massess_bayes_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0maccuracy_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-179598895b0a>\u001b[0m in \u001b[0;36massess_bayes_net\u001b[0;34m(model, dataframe, var)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mBayesian\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifying\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcases\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     ''' \n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "import time\n",
    "s = time.time()\n",
    "acc, stddev = cross_validation_bayes_net(G, data, 'BC')\n",
    "print(f\"Average accuracy: {acc} ¬± {stddev}\")\n",
    "e = time.time()\n",
    "print(\"Time of cv_bayes_net\", round(e-s,2))\n",
    "\n",
    "######################\n",
    "# Test code to copy  #\n",
    "######################\n",
    "\n",
    "import time\n",
    "s = time.time()\n",
    "acc, stddev = cross_validation_bayes_net(G, small_data, 'BC')\n",
    "print(f\"Average accuracy: {acc} ¬± {stddev}\")\n",
    "e = time.time()\n",
    "print(\"Time of cv_bayes_net\", round(e-s,2))\n",
    "test(abs(acc-0.841) < 0.01)\n",
    "test(abs(stddev - 0.02) < 0.015)\n",
    "test(stddev > 0)\n",
    "test(e-s < 5)\n",
    "test(e-s < 10)\n",
    "test(e-s < 30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 8 - Na√Øve Bayes classifier structure\n",
    "\n",
    "Let's work now with the Na√Øve Bayes classifier. This classifier is a Bayesian network with a pre-defined structure (graph). Let's start creating a new function, ``learn_naive_bayes_structure(dataframe, class_var)``, that learns the Na√Øve Bayes graph structure from a pandas `dataframe` using `class_var` as the class variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_naive_bayes_structure(dataframe, class_var) in this cell\n",
    "\n",
    "def learn_naive_bayes_structure(dataframe, class_var):\n",
    "    '''\n",
    "    Arguments:\n",
    "        dataframe:   A pandas dataframe\n",
    "        class_var:   Variable identifier to be classified\n",
    "    Returns:\n",
    "        A Graph object with the structure of the Na√Øve Bayes classifier for the attributes in dataframe\n",
    "    '''\n",
    "    cols = list(dataframe.columns)\n",
    "    cols.remove(class_var)\n",
    "    \n",
    "    graph_dict = {}\n",
    "    for col in cols:\n",
    "        graph_dict[col] = []\n",
    "    graph_dict[class_var] = cols\n",
    "    \n",
    "    g = Graph(graph_dict)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 6.0.1 (20220911.1526)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"681pt\" height=\"606pt\"\n",
       " viewBox=\"0.00 0.00 680.65 605.54\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 601.54)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-601.54 676.65,-601.54 676.65,4 -4,4\"/>\n",
       "<!-- BreastDensity -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>BreastDensity</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"60.44\" cy=\"-337.48\" rx=\"60.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"60.44\" y=\"-333.78\" font-family=\"Times,serif\" font-size=\"14.00\">BreastDensity</text>\n",
       "</g>\n",
       "<!-- Location -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Location</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"630.4\" cy=\"-311.09\" rx=\"42.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"630.4\" y=\"-307.39\" font-family=\"Times,serif\" font-size=\"14.00\">Location</text>\n",
       "</g>\n",
       "<!-- Age -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Age</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"269.23\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"269.23\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Age</text>\n",
       "</g>\n",
       "<!-- Mass -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>Mass</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"367.88\" cy=\"-579.54\" rx=\"29.8\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"367.88\" y=\"-575.84\" font-family=\"Times,serif\" font-size=\"14.00\">Mass</text>\n",
       "</g>\n",
       "<!-- AD -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>AD</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"493.24\" cy=\"-529.55\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"493.24\" y=\"-525.85\" font-family=\"Times,serif\" font-size=\"14.00\">AD</text>\n",
       "</g>\n",
       "<!-- MC -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>MC</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"234.98\" cy=\"-547.14\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.98\" y=\"-543.44\" font-family=\"Times,serif\" font-size=\"14.00\">MC</text>\n",
       "</g>\n",
       "<!-- Size -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>Size</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"140.86\" cy=\"-88.22\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"140.86\" y=\"-84.52\" font-family=\"Times,serif\" font-size=\"14.00\">Size</text>\n",
       "</g>\n",
       "<!-- Shape -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>Shape</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"610.38\" cy=\"-178.3\" rx=\"32.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"610.38\" y=\"-174.6\" font-family=\"Times,serif\" font-size=\"14.00\">Shape</text>\n",
       "</g>\n",
       "<!-- FibrTissueDev -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>FibrTissueDev</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"113.18\" cy=\"-216.42\" rx=\"63.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"113.18\" y=\"-212.72\" font-family=\"Times,serif\" font-size=\"14.00\">FibrTissueDev</text>\n",
       "</g>\n",
       "<!-- SkinRetract -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>SkinRetract</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"531.2\" cy=\"-64.71\" rx=\"51.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"531.2\" y=\"-61.01\" font-family=\"Times,serif\" font-size=\"14.00\">SkinRetract</text>\n",
       "</g>\n",
       "<!-- NippleDischarge -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>NippleDischarge</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"400.99\" cy=\"-28.16\" rx=\"70.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"400.99\" y=\"-24.46\" font-family=\"Times,serif\" font-size=\"14.00\">NippleDischarge</text>\n",
       "</g>\n",
       "<!-- Spiculation -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>Spiculation</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"129.43\" cy=\"-463.41\" rx=\"50.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"129.43\" y=\"-459.71\" font-family=\"Times,serif\" font-size=\"14.00\">Spiculation</text>\n",
       "</g>\n",
       "<!-- Margin -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>Margin</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"598.04\" cy=\"-443.78\" rx=\"37.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"598.04\" y=\"-440.08\" font-family=\"Times,serif\" font-size=\"14.00\">Margin</text>\n",
       "</g>\n",
       "<!-- BC -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>BC</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"353.5\" cy=\"-293.44\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"353.5\" y=\"-289.74\" font-family=\"Times,serif\" font-size=\"14.00\">BC</text>\n",
       "</g>\n",
       "<!-- BC&#45;&gt;BreastDensity -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>BC&#45;&gt;BreastDensity</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M326.98,-297.43C281.67,-304.24 188.12,-318.3 124.81,-327.81\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"123.9,-324.41 114.53,-329.36 124.94,-331.33 123.9,-324.41\"/>\n",
       "</g>\n",
       "<!-- BC&#45;&gt;Location -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>BC&#45;&gt;Location</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M380.56,-295.17C426.26,-298.08 519.5,-304.02 578.25,-307.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"578.24,-311.27 588.45,-308.41 578.69,-304.28 578.24,-311.27\"/>\n",
       "</g>\n",
       "<!-- BC&#45;&gt;Age -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>BC&#45;&gt;Age</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M348.1,-275.79C333.81,-229.07 294.89,-101.89 277.65,-45.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"280.96,-44.4 274.69,-35.86 274.27,-46.45 280.96,-44.4\"/>\n",
       "</g>\n",
       "<!-- BC&#45;&gt;Mass -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>BC&#45;&gt;Mass</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M354.42,-311.77C356.87,-360.42 363.53,-493.04 366.46,-551.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"362.97,-551.55 366.96,-561.36 369.96,-551.2 362.97,-551.55\"/>\n",
       "</g>\n",
       "<!-- BC&#45;&gt;AD -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>BC&#45;&gt;AD</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M363.55,-310.42C387.77,-351.35 449.49,-455.63 478.17,-504.08\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"475.18,-505.9 483.28,-512.72 481.2,-502.34 475.18,-505.9\"/>\n",
       "</g>\n",
       "<!-- BC&#45;&gt;MC -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>BC&#45;&gt;MC</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M345.35,-310.88C324.96,-354.53 271.63,-468.7 247.34,-520.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"244.08,-519.38 243.02,-529.92 250.43,-522.34 244.08,-519.38\"/>\n",
       "</g>\n",
       "<!-- BC&#45;&gt;Size -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>BC&#45;&gt;Size</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M337.87,-278.35C300.68,-242.46 206.84,-151.9 163.47,-110.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"165.86,-107.48 156.23,-103.05 160.99,-112.52 165.86,-107.48\"/>\n",
       "</g>\n",
       "<!-- BC&#45;&gt;Shape -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>BC&#45;&gt;Shape</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M376.3,-283.22C421.38,-263.02 522.18,-217.84 575.6,-193.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"577.31,-196.96 585,-189.67 574.44,-190.57 577.31,-196.96\"/>\n",
       "</g>\n",
       "<!-- BC&#45;&gt;FibrTissueDev -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>BC&#45;&gt;FibrTissueDev</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M329.14,-285.63C290.88,-273.37 215.85,-249.32 165.1,-233.06\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"165.89,-229.64 155.3,-229.92 163.75,-236.3 165.89,-229.64\"/>\n",
       "</g>\n",
       "<!-- BC&#45;&gt;SkinRetract -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>BC&#45;&gt;SkinRetract</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M366,-277.36C396.4,-238.22 474.45,-137.75 511.33,-90.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"514.13,-92.37 517.51,-82.33 508.61,-88.08 514.13,-92.37\"/>\n",
       "</g>\n",
       "<!-- BC&#45;&gt;NippleDischarge -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>BC&#45;&gt;NippleDischarge</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M356.77,-275.21C364.92,-229.67 386.22,-110.68 395.98,-56.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"399.45,-56.63 397.77,-46.17 392.56,-55.4 399.45,-56.63\"/>\n",
       "</g>\n",
       "<!-- BC&#45;&gt;Spiculation -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>BC&#45;&gt;Spiculation</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M335.54,-307.07C297.04,-336.27 206.23,-405.16 159.05,-440.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.89,-438.19 151.04,-447.02 161.12,-443.76 156.89,-438.19\"/>\n",
       "</g>\n",
       "<!-- BC&#45;&gt;Margin -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>BC&#45;&gt;Margin</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M373.51,-305.75C415.91,-331.81 515.08,-392.78 566.25,-424.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"564.57,-427.31 574.92,-429.57 568.23,-421.35 564.57,-427.31\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fd5883e6160>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "naiveG = learn_naive_bayes_structure(data, 'BC')\n",
    "naiveG.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 9 - Na√Øve Bayes classification\n",
    "\n",
    "As the Na√Øve Bayes classifier is a Bayesian network, we can use the existing `BayesNet` class to create a new class `NaiveBayes`.\n",
    "\n",
    "Let's create a new method ``model.predict_log(class_var, evidence)`` that implements the classification with complete data. This function should return the MPE value for the attribute `class_var` given the `evidence`. As we work with complete data, `evidence` is an instantiation for all variables but `class_var`. **Use the log probability trick discussed in the lectures to classify each example**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for predict_log(self, class_var, evidence) in this cell\n",
    "\n",
    "class NaiveBayes(BayesNet):\n",
    "    def predict_log(self, class_var, evidence):\n",
    "        '''\n",
    "        Arguments:\n",
    "            class_var:   Variable identifier to be classified\n",
    "            evidence:    Python dictionary with one instantiation to all variables but class_var\n",
    "        Returns:\n",
    "            The MPE value (class label) of class_var given evidence\n",
    "        '''        \n",
    "        result = Factor(self.factors[class_var].domain, self.factors[class_var].outcomeSpace)\n",
    "        for outcome in self.factors[class_var].outcomeSpace[class_var]:\n",
    "            result[outcome] += (np.log(self.factors[class_var][outcome]) - 1/3)\n",
    "            \n",
    "        \n",
    "        for node, evi in evidence.items():\n",
    "            for outcome in self.factors[class_var].outcomeSpace[class_var]:\n",
    "                result[outcome] += np.log( self.factors[node][(outcome, evi)] )       \n",
    "        \n",
    "        index = np.argmax(result.table)\n",
    "        return result.outcomeSpace[class_var][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "## Note: More hidden tests will be used. You should make more tests yourself.\n",
    "\n",
    "outcomeSpace = learn_outcome_space(data)\n",
    "naiveG = learn_naive_bayes_structure(data, 'BC')\n",
    "naive_model = NaiveBayes(naiveG, outcomeSpace=outcomeSpace)\n",
    "naive_model.learn_parameters(data, alpha=1)\n",
    "evidence = {'Age': '35-49', \n",
    "    'Location': 'LolwOutQuad', \n",
    "    'MC': 'No', \n",
    "    'SkinRetract': 'No', \n",
    "    'NippleDischarge': 'No',\n",
    "    'AD': 'No',\n",
    "    'FibrTissueDev': 'No', \n",
    "    'Spiculation': 'No',\n",
    "    'Margin': 'Well-defined', \n",
    "    'Mass': 'No',\n",
    "    'Shape': 'Other', \n",
    "    'Size': '<1cm',\n",
    "    'BreastDensity': 'high'}\n",
    "\n",
    "test(naive_model.predict_log('BC', evidence) == 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-f4a531ca9028>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mevidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mevidence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnaive_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevidence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'No'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mevidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-e2792a7d23b9>\u001b[0m in \u001b[0;36mpredict_log\u001b[0;34m(self, class_var, evidence)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutcomeSpace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0moutcome\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutcomeSpace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/COMP9418/Assignment1/DiscreteFactors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, outcomes)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# convert outcomes into array indicies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutcomeSpace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcomes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/COMP9418/Assignment1/DiscreteFactors.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# convert outcomes into array indicies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutcomeSpace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcomes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "outcomeSpace = learn_outcome_space(data)\n",
    "naiveG = learn_naive_bayes_structure(data, 'BC')\n",
    "naive_model = NaiveBayes(naiveG, outcomeSpace=outcomeSpace)\n",
    "naive_model.learn_parameters(data, alpha=1)\n",
    "\n",
    "evidence = data.iloc[42].to_dict()\n",
    "del evidence['BC']\n",
    "test(naive_model.predict_log('BC', evidence) == 'No')\n",
    "\n",
    "evidence = data.iloc[42].to_dict()\n",
    "del evidence['AD']\n",
    "test(naive_model.predict_log('AD', evidence) == 'No')\n",
    "\n",
    "evidence = data.iloc[42].to_dict()\n",
    "del evidence['Size']\n",
    "test(naive_model.predict_log('Size', evidence) == '<1cm')\n",
    "\n",
    "evidence = data.iloc[42].to_dict()\n",
    "del evidence['Margin']\n",
    "test(naive_model.predict_log('Margin', evidence) == 'Well-defined')\n",
    "\n",
    "evidence = data.iloc[42].to_dict()\n",
    "del evidence['BreastDensity']\n",
    "test(naive_model.predict_log('BreastDensity', evidence) == 'medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 10 - Na√Øve Bayes accuracy estimation\n",
    "\n",
    "Design a new function ``assess_naive_bayes(model, dataframe, class_var)`` that uses the test cases in ``dataframe`` to assess the performance of the Na√Øve Bayes classifier for the class variable `class_var`. This function will return the accuracy of the classifier according to the examples in the ``dataframe``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for assess_naive_bayes(model, dataframe, class_var) in this cell\n",
    "\n",
    "#model = NaiveBayes(...)\n",
    "def assess_naive_bayes(model, dataframe, class_var='BC'):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model:      Naive Bayes object\n",
    "        dataframe:  a Pandas dataframe object\n",
    "        class_var:  Variable identifier to be classified\n",
    "    Returns:\n",
    "        The accuracy of the Naive Bayes model in classifying the cases in dataframe\n",
    "    '''      \n",
    "    count, correct = 0, 0\n",
    "    records = dataframe.to_dict(orient='records')\n",
    "    for row in records:\n",
    "        # print(f'currently predicting: {count}')\n",
    "        Y = row.pop(class_var)\n",
    "        Y_hat = model.predict_log(class_var, row)\n",
    "        \n",
    "        if Y == Y_hat: correct += 1\n",
    "        count += 1\n",
    "    \n",
    "    return correct / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "## Note: More hidden tests will be used. You should make more tests yourself.\n",
    "\n",
    "naive_model = NaiveBayes(naiveG, outcomeSpace)\n",
    "naive_model.learn_parameters(data, alpha=1)\n",
    "\n",
    "acc = assess_naive_bayes(naive_model, data, 'BC')\n",
    "test(abs(acc-0.7926) < 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Test code to copy  #\n",
    "######################\n",
    "\n",
    "### -------- Initialize model -----------\n",
    "def true_learn_naive_bayes_structure(data, class_var):\n",
    "    # create graph\n",
    "    var_names = [key for key in data]\n",
    "    graph = dict([(v,[]) for v in var_names])\n",
    "    var_names.remove(class_var)\n",
    "    for var in var_names:\n",
    "        graph[class_var].append(var)\n",
    "    return Graph(graph)\n",
    "\n",
    "true_graph = true_learn_naive_bayes_structure(data, 'BC')\n",
    "# ----------------------------------------\n",
    "\n",
    "naiveG = learn_naive_bayes_structure(data, 'BC')\n",
    "\n",
    "for v in true_graph:\n",
    "    test(len(true_graph.adj_list[v]) == len(naiveG.adj_list[v]) and set(true_graph.adj_list[v]) == set(naiveG.adj_list[v]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes(BayesNet):\n",
    "    def predict_log(self, class_var, evidence):\n",
    "        '''\n",
    "        Arguments:\n",
    "            class_var:   Variable identifier to be classified\n",
    "            evidence:    Python dictionary with one instantiation to all variables but class_var\n",
    "        Returns:\n",
    "            The MPE value (class label) of class_var given evidence\n",
    "        '''          \n",
    "        # get necessary factors\n",
    "        relevant_factor_names = set(self.graph.children(class_var))\n",
    "        relevant_factor_names.add(class_var)\n",
    "        relevant_factors = dict((var, self.factors[var]) for var in relevant_factor_names)\n",
    "        # add evidence to all factors\n",
    "        for name in relevant_factors.keys():\n",
    "            relevant_factors[name] = np.log(relevant_factors[name].evidence(**evidence).table)\n",
    "\n",
    "        # join all factors\n",
    "        f = np.zeros(len(self.outcomeSpace[class_var])) # trivial factor\n",
    "        for fac in relevant_factors.values():\n",
    "            f += fac\n",
    "        \n",
    "        # get row with maximum probability\n",
    "        return self.outcomeSpace[class_var][np.argmax(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If these tests break, try changing the \n",
      "dataset to full sized (and deduct 1 mark).\n",
      "Note that the tests are designed for the small dataset\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "print(\"If these tests break, try changing the \\ndataset to full sized (and deduct 1 mark).\\nNote that the tests are designed for the small dataset\")\n",
    "small_data = data.head(2000)\n",
    "\n",
    "# Testing basic assess\n",
    "true_graph = true_learn_naive_bayes_structure(small_data, 'BC')\n",
    "naive_model = NaiveBayes(true_graph, outcomeSpace)\n",
    "naive_model.learn_parameters(data)\n",
    "acc = assess_naive_bayes(naive_model, small_data, 'BC')\n",
    "test(abs(acc-0.7885) < 0.001)\n",
    "\n",
    "true_graph = true_learn_naive_bayes_structure(small_data, 'FibrTissueDev')\n",
    "naive_model = NaiveBayes(true_graph, outcomeSpace)\n",
    "naive_model.learn_parameters(data)\n",
    "acc = assess_naive_bayes(naive_model, small_data, 'FibrTissueDev')\n",
    "test(abs(acc-0.7905) < 0.001)\n",
    "\n",
    "true_graph = true_learn_naive_bayes_structure(small_data, 'Location')\n",
    "naive_model = NaiveBayes(true_graph, outcomeSpace)\n",
    "naive_model.learn_parameters(data)\n",
    "acc = assess_naive_bayes(naive_model, small_data, 'Location')\n",
    "test(abs(acc-0.267) < 0.001)\n",
    "\n",
    "true_graph = true_learn_naive_bayes_structure(small_data, 'Age')\n",
    "naive_model = NaiveBayes(true_graph, outcomeSpace)\n",
    "naive_model.learn_parameters(data)\n",
    "acc = assess_naive_bayes(naive_model, small_data, 'Age')\n",
    "test(abs(acc-0.3815) < 0.001)\n",
    "\n",
    "true_graph = true_learn_naive_bayes_structure(small_data, 'NippleDischarge')\n",
    "naive_model = NaiveBayes(true_graph, outcomeSpace)\n",
    "naive_model.learn_parameters(data)\n",
    "acc = assess_naive_bayes(naive_model, small_data, 'NippleDischarge')\n",
    "test(abs(acc-0.7525) < 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 11 - Na√Øve Bayes assessment with cross-validation\n",
    "\n",
    "Implement a function called `cross_validation_naive_bayes(dataframe, class_var, k)`, compute and report the average accuracy over the $k=10$-fold cross-validation runs as well as the standard deviation. A scaffold for this function is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for cross_validation_naive_bayes(dataframe, class_var, k) in this cell\n",
    "\n",
    "def cross_validation_naive_bayes(dataframe, class_var='BC', k=10):\n",
    "    accuracy_list = []\n",
    "    \n",
    "    kf = KFold(n_splits=k, shuffle = True, random_state = 42)\n",
    "    for train, test in kf.split(dataframe):\n",
    "      \n",
    "        # train a model with learn_parameters\n",
    "        model = NaiveBayes(naiveG, outcomeSpace)\n",
    "        model.learn_parameters(train, alpha=1)\n",
    "        \n",
    "        # test the model with assess_bayes_net\n",
    "        acc = assess_naive_bayes(model, test, class_var)\n",
    "        \n",
    "        accuracy_list.append(acc)\n",
    "    return np.mean(accuracy_list), np.std(accuracy_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken = 0:00:59.532526\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "start = dt.now()\n",
    "acc, stddev = cross_validation_naive_bayes(data, 'BC')\n",
    "print(f'time taken = {dt.now() - start}')\n",
    "test(abs(acc - 0.80) < 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-f45b759c5e98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation_naive_bayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Time of cv_naive_bayes: {e-s}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-e10a20a4005c>\u001b[0m in \u001b[0;36mcross_validation_naive_bayes\u001b[0;34m(dataframe, class_var, k)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# test the model with assess_bayes_net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massess_naive_bayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0maccuracy_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-55fdd5323574>\u001b[0m in \u001b[0;36massess_naive_bayes\u001b[0;34m(model, dataframe, class_var)\u001b[0m\n\u001b[1;32m     12\u001b[0m     '''      \n\u001b[1;32m     13\u001b[0m     \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# print(f'currently predicting: {count}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_dict'"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Test code to copy  #\n",
    "######################\n",
    "\n",
    "# Testing cross_validation\n",
    "import time\n",
    "s = time.time()\n",
    "acc, stddev = cross_validation_naive_bayes(small_data, 'BC')\n",
    "e = time.time()\n",
    "print(f\"Time of cv_naive_bayes: {e-s}\")\n",
    "\n",
    "\n",
    "# Testing efficiency\n",
    "test(e-s < 5)\n",
    "test(e-s < 7)\n",
    "test(e-s < 12)\n",
    "test(abs(acc-0.7885) < 0.01)\n",
    "test(stddev > 0 and stddev < 0.04)\n",
    "\n",
    "acc, stddev = cross_validation_naive_bayes(small_data, 'MC', 3)\n",
    "test(abs(acc - 0.81) < 0.05)\n",
    "\n",
    "acc, stddev = cross_validation_naive_bayes(small_data, 'Location', 8)\n",
    "test(abs(acc - 0.26) < 0.03)\n",
    "\n",
    "# Testing log probabilities\n",
    "print(\"manually check that the student used log probabilities. Assign zero marks if not\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [15 Marks] Task 12 - Tree-augmented na√Øve Bayes structure\n",
    "\n",
    "Let's work now with the Tree-augmented Na√Øve Bayes classifier. We will start creating a new function, ``learn_tan_structure(dataframe, class_var)``, that learns the Tree-augmented Bayes graph structure from a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factor_by_node(node, dataframe, alpha=1):\n",
    "    factor = Factor([node], learn_outcome_space(dataframe))\n",
    "    marginal_p = (dataframe[node].value_counts() + alpha) / (dataframe[node].count() + alpha * dataframe[node].value_counts().shape[0])\n",
    "    for outcome in marginal_p.index:\n",
    "        factor.__setitem__(outcome, marginal_p[outcome])\n",
    "    return factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph(Graph):\n",
    "    \n",
    "    def set_edge_weight(self, node1, node2, weight, undirected=True):\n",
    "        self.edge_weights[(node1,node2)] = weight\n",
    "        if undirected:\n",
    "            self.edge_weights[(node2,node1)] = weight\n",
    "    \n",
    "    def prim_max(self, s):\n",
    "        visited = [s]\n",
    "        Q = []\n",
    "        tree = Graph()\n",
    "        for e in self.adj_list[s]:\n",
    "            pq.heappush(Q, (-self.edge_weights[(s,e)], s, e))\n",
    "        while len(Q) > 0:\n",
    "            weight, v, u = pq.heappop(Q)\n",
    "            if u not in visited:\n",
    "                visited.append(u)\n",
    "                tree.add_edge(v, u, -weight)\n",
    "                for e in self.adj_list[u]:\n",
    "                    if e not in visited:\n",
    "                        pq.heappush(Q, (-self.edge_weights[(u,e)], u, e))        \n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_tan_structure(dataframe, class_var) in this cell\n",
    "\n",
    "def learn_tan_structure(dataframe, class_var):\n",
    "    '''\n",
    "    Arguments:\n",
    "        dataframe - A pandas dataframe\n",
    "        class_var - Variable identifier to be classified\n",
    "    Returns:\n",
    "        A Graph object with the structure of the Na√Øve Bayes classifier for the attributes in dataframe and class_var\n",
    "    '''\n",
    "    nodes = list(dataframe.columns)\n",
    "    nodes.remove(class_var)\n",
    "    graph_dict = {}\n",
    "    for node in nodes:\n",
    "        neighbours = copy.deepcopy(nodes)\n",
    "        neighbours.remove(node)\n",
    "        graph_dict[node] = neighbours\n",
    "    tan_graph = Graph(graph_dict)\n",
    "    \n",
    "    outcomeSpace = learn_outcome_space(dataframe)\n",
    "    \n",
    "    \n",
    "    for idx1, var1 in enumerate(nodes):\n",
    "        for idx2, var2 in enumerate(nodes):\n",
    "            if var1 == var2: continue\n",
    "\n",
    "            accum = 0\n",
    "            for outcome_1 in outcomeSpace[var1]:\n",
    "                for outcome_2 in outcomeSpace[var2]:\n",
    "                    for outcome_bc in outcomeSpace[class_var]:\n",
    "                        \n",
    "                        class_var_count = dataframe[dataframe[class_var] == outcome_bc].shape[0]\n",
    "                        joint = dataframe[(dataframe[var1] == outcome_1) & (dataframe[var2] == outcome_2) & (dataframe[class_var] == outcome_bc)]\n",
    "\n",
    "                        tmp1 = joint.shape[0] / class_var_count\n",
    "                        tmp2 = dataframe[(dataframe[var1] == outcome_1) & (dataframe[class_var] == outcome_bc)].shape[0] / class_var_count\n",
    "                        tmp3 = dataframe[(dataframe[var2] == outcome_2) & (dataframe[class_var] == outcome_bc)].shape[0] / class_var_count\n",
    "                        \n",
    "                        if tmp1 == 0: continue\n",
    "                        tmp = np.log2(tmp1) - np.log2(tmp2) - np.log2(tmp3)\n",
    "                        tmp *= joint.shape[0] / data.shape[0]\n",
    "                        accum += tmp\n",
    "                        \n",
    "            tan_graph.set_edge_weight(var1, var2, float(accum))\n",
    "    \n",
    "    max_tree = tan_graph.prim_max(nodes[0])\n",
    "    for node in nodes:\n",
    "        max_tree.add_edge(class_var, node)\n",
    "        \n",
    "    return max_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "tan_graph = learn_tan_structure(data, class_var='BC')\n",
    "\n",
    "test(len(tan_graph.children('BC')) == len(tan_graph)-1)\n",
    "test('FibrTissueDev' in tan_graph.children('Spiculation') or 'Spiculation' in tan_graph.children('FibrTissueDev'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed test case !!!\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n",
      "Testing structure learning on lecture dataset\n",
      "Passed test case\n",
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Test code to copy  #\n",
    "######################\n",
    "import time\n",
    "\n",
    "s = time.time()\n",
    "tan_graph = learn_tan_structure(data.head(2000), 'BC')\n",
    "e = time.time()\n",
    "\n",
    "test(e-s < 5)\n",
    "test(e-s < 15)\n",
    "\n",
    "# Check that the graph has the correct number of edges\n",
    "sum_edges = 0\n",
    "for node, children in tan_graph.adj_list.items():\n",
    "    if node != 'BC':\n",
    "        sum_edges += len(children)\n",
    "test(sum_edges == len(tan_graph)-2) #number of edges counted in the tree is num nodes in tree - 1 (which is nodes in graph-2 since BC doesn't count)\n",
    "\n",
    "# Check that each node has at most 2 parents\n",
    "GT = dict((v, []) for v in tan_graph)\n",
    "for v in tan_graph:\n",
    "    for w in tan_graph.children(v):\n",
    "        GT[w].append(v)\n",
    "less_than_two_parents = True\n",
    "for node in GT:\n",
    "    if(len(GT[node])>2):\n",
    "        less_than_two_parents = False\n",
    "test(less_than_two_parents)\n",
    "\n",
    "print(\"Testing structure learning on lecture dataset\")\n",
    "\n",
    "# lecture dataset\n",
    "data2 = {}\n",
    "data2['A1'] = [1,1,1,0,1,1,1,0,0,1]\n",
    "data2['A2'] = [1,0,0,1,1,0,1,0,1,1]\n",
    "data2['A3'] = [0,1,1,1,1,1,0,0,1,1]\n",
    "data2['A4'] = [1,1,1,1,0,1,0,1,1,0]\n",
    "data2['C']  = [0,1,1,1,0,1,0,0,1,0]\n",
    "outcomeSpace2 = {\n",
    "    'A1':(0,1),\n",
    "    'A2':(0,1),\n",
    "    'A3':(0,1),\n",
    "    'A4':(0,1),\n",
    "    'C':(0,1),\n",
    "    }\n",
    "data2 = pd.DataFrame.from_dict(data2)\n",
    "graph2 = learn_tan_structure(data2, 'C')\n",
    "graph2.show()\n",
    "test('A2' in graph2.children('A1') or 'A1' in graph2.children('A2'))\n",
    "test('A4' in graph2.children('A2') or 'A2' in graph2.children('A4') or 'A4' in graph2.children('A1') or 'A1' in graph2.children('A4'))\n",
    "test('A3' in graph2.children('A4') or 'A4' in graph2.children('A3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 13 - Tree-augmented na√Øve Bayes assessment with cross-validation\n",
    "\n",
    "Implement a function called `cross_validation_tan(dataframe, class_var, k)`, compute and report the average accuracy over the $k=10$-fold cross-validation runs and the standard deviation. A scaffold for this function is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83425"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def assess_tan(model, dataframe, class_var='BC'):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model:     Bayesian Network object\n",
    "        dataframe: a Pandas dataframe object\n",
    "        class_var: Variable identifier to be classified\n",
    "    Returns:\n",
    "        The accuracy of the Bayesian network model in classifying the cases in dataframe\n",
    "    '''     \n",
    "    count, correct = 0, 0\n",
    "    records = data.to_dict(orient='records')\n",
    "    for row in records:\n",
    "        #print(f'currently predicting: {count}')\n",
    "        Y = row.pop(class_var)\n",
    "        Y_hat = model.predict(class_var, row)\n",
    "        \n",
    "        if Y == Y_hat:\n",
    "            correct += 1\n",
    "        count += 1\n",
    "    \n",
    "    return correct / count\n",
    "\n",
    "outcomeSpace = learn_outcome_space(data)\n",
    "tan_graph = learn_tan_structure(data, class_var='BC')\n",
    "model = BayesNet(tan_graph, outcomeSpace=outcomeSpace)\n",
    "\n",
    "model.learn_parameters(data, alpha=1)\n",
    "assess_tan(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for cross_validation_tan(dataframe, class_var, k) in this cell\n",
    "\n",
    "def cross_validation_tan(dataframe, class_var='BC', k=10):\n",
    "    accuracy_list = []\n",
    "    \n",
    "    kf = KFold(n_splits=k, shuffle = True, random_state = 42)\n",
    "    for train, test in kf.split(dataframe):\n",
    "      \n",
    "        # train a model with learn_parameters\n",
    "        model = BayesNet(tan_graph, outcomeSpace)\n",
    "        model.learn_parameters(train, alpha=1)\n",
    "        \n",
    "        # test the model with assess_bayes_net\n",
    "        acc = assess_tan(model, test, class_var)\n",
    "        \n",
    "        accuracy_list.append(acc)\n",
    "    return np.mean(accuracy_list), np.std(accuracy_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken = 0:08:45.316942\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "start = dt.now()\n",
    "acc, stddev = cross_validation_tan(data, 'BC')\n",
    "print(f'time taken = {dt.now() - start}')\n",
    "test(abs(acc - 0.83) < 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 14 - Report\n",
    "\n",
    "Write a report (**with less than 500 words**) summarising your findings in this assignment. Your report should address the following:\n",
    "\n",
    "a. Make a summary and discussion of the experimental results. You can analyse your results from different aspects such as accuracy, runtime, coding complexity and independence assumptions. You can use plots to illustrate your results.\n",
    "\n",
    "b. Discuss the time and memory complexity of the implemented algorithms.\n",
    "\n",
    "Use Markdown and Latex to write your report in the Jupyter notebook. Develop some plots using Matplotlib to illustrate your results. Be mindful of the maximum number of words. Please, be concise and objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The Bayesian network has the highest accuracy at around 85%, the TAN has the seccond highest accuracy at 83%, and Naive Bayes has the lowest at 80%. \n",
    "\n",
    "The Naive Bayes has low accuracy partly from its independence assumptions, it assumes that all features are independent conditioned on the class variable (BC), which is not true. For the Bayesian network, the independence assumption is given by the graph's structure and Markovian assumption. The TAN has no independence assumption among variables to construct the tree structure, it uses largest conditional Mutual Information to construct the max spanning tree.\n",
    "\n",
    "Naive Bayes is the easiest to code, it is a tree with the class variable as the root and all other variables as leaves. Bayesian network is second easiest to code, however, it requires domain knowledge to produce the DAG. The TAN is the most complex to code and implement, it requires computing pairwise Mutual Information, producing a max spanning tree and obtain the graph structure. \n",
    "\n",
    "The runtime also reflects the ease of coding and algorithm complexity. Using the same data and 10 fold cross-validation, Naive Bayes takes the shortest to run (0:59), Bayesian network is second shortest (5:28), and TAN takes the longest (8:45), as producing TAN requires much more steps than the others. \n",
    "\n",
    "Naive Bayes: time complexity is O(n * c) where n is the number of independent variables and c is the number of classes; space complexity is O(n * c) too, as there are n conditional probability tables, each with c entries representing different class values.\n",
    "\n",
    "Bayesian network: time complexity is O(n * c) where n is the number of independent variables and c is the number of classes; for each CPT, if the max number of parents for each variable is k, then the size of each CPT is O(c^(k+1)), given there are n variables, the space complexity is O(n * c^(k+1))\n",
    "\n",
    "TAN: time complexity for computing network structure is O(n * n * c) where n is the number of independent variables and c is the number of classes, time complexity for making prediction is O(n * c); the space complexity for computing network structure is O(n * d), where d is the number of entries on the data table, i.e. it takes the entire table in memory. the space complexity for storing CPT is O(n * c^(k+1)), same reasoning as the above.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
